toxic_detection_prompt =  """ 
在这项任务中，您要进行毒性检测。请基于下述对话，利用您的理解和分析来识别其中的毒性类型，并对其毒性水平进行0-10的打分。毒性类型包括：冲突、讽刺、歧视、不尊重、模糊、避让和冒犯。具体地说，您要确认对话的毒性水平以及其所属的不良行为类别。如果您认为对话中没有毒性，那么类别设为“无”，分数为0。
对话内容为{dialogue}
请按照JSON格式返回结果：
{{ "labels": "<>", "score": "<>" }}
"""